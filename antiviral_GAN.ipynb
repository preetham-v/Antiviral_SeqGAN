{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "antiviral_GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yAb5ZeeIA4e0"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNd4iL+tx9U7hJ+XDqHHp15",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preetham-v/antiviralGAN/blob/master/antiviral_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAb5ZeeIA4e0",
        "colab_type": "text"
      },
      "source": [
        "##SimpleGAN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UvVxFsCD9mT",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwA9cE0NHuh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/preetham-v/antiviralGAN/master/AVPdb_data.csv'\n",
        "\n",
        "data = pd.read_csv(url, skiprows = 1, usecols = range(3), header=None, names=['ID','seq','len'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPnBUMVMJEK8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "720e239a-2934-4ed8-c4d9-8e397b36c85a"
      },
      "source": [
        "all_sequences = np.asarray(data['seq'])\n",
        "print(all_sequences[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['PYVGSGLYRR' 'SMIENLEYM' 'ECRSTSYAGAVVNDL' 'STSYAGAVVNDL' 'YAGAVVNDL']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQinJOXdHrU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dictionary of 20 canonical amino acids\n",
        "CHARACTER_DICT = set([\n",
        "    u'A', u'C', u'E', u'D', u'G', u'F', u'I', u'H', u'K',\n",
        "    u'M', u'L', u'N', u'Q', u'P', u'S', u'R', u'T', u'W',\n",
        "    u'V', u'Y']\n",
        ")\n",
        "\n",
        "CHARACTER_TO_INDEX = {\n",
        "    character: i\n",
        "    for i, character in enumerate(CHARACTER_DICT)\n",
        "}\n",
        "\n",
        "INDEX_TO_CHARACTER = {\n",
        "    CHARACTER_TO_INDEX[c]: c\n",
        "    for c in CHARACTER_TO_INDEX\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eqm5jJ_NG1pG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 18 #Problem Statement requires < 2000 kDa, Avg. amino acid = 110 kDa\n",
        "num_amino_acids = len(CHARACTER_DICT) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qCHSqHfIOg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sequence_to_vector(sequence, embed_dict=None):\n",
        "    if embed_dict==None:\n",
        "        default = np.zeros([MAX_SEQUENCE_LENGTH, len(CHARACTER_TO_INDEX)+1])\n",
        "        default[:,len(CHARACTER_TO_INDEX)] = 1\n",
        "        for i, character in enumerate(sequence[:MAX_SEQUENCE_LENGTH]):\n",
        "            default[i][CHARACTER_TO_INDEX[character]] = 1\n",
        "            default[i][len(CHARACTER_TO_INDEX)] = 0\n",
        "        return default\n",
        "    else:\n",
        "        default = np.zeros([MAX_SEQUENCE_LENGTH,len(embed_dict['A'])])\n",
        "        for i, character in enumerate(sequence[:MAX_SEQUENCE_LENGTH]):\n",
        "            for k,val in enumerate(embed_dict[character]):\n",
        "                default[i,k] = val\n",
        "        return default"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KFAejGUmdnQz",
        "colab": {}
      },
      "source": [
        "def vector_to_sequence(vector):\n",
        "    seq = ''\n",
        "\n",
        "    for i in range(18):\n",
        "        arg = np.argmax(vector[i])\n",
        "        if arg == 20:\n",
        "          seq += 'X'\n",
        "        else:\n",
        "          seq += INDEX_TO_CHARACTER[arg]\n",
        "    return seq\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXYPLrCaQnXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_length):\n",
        "        \"\"\"A generator for mapping a random peptide to an antiviral peptide\n",
        "        Args:\n",
        "            input_length (int array): max_length * number_of_characters \n",
        "                                      (\"noise vector\")\n",
        "            layers (List[int]): A list of layer widths including output width\n",
        "            output_activation: torch activation function or None\n",
        "        \"\"\"\n",
        "        super(Generator, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_length, 40)\n",
        "        self.leaky_relu = nn.LeakyReLU()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(40, 120)\n",
        "        self.linear3 = nn.Linear(120, 240)\n",
        "        self.linear4 = nn.Linear(240, 378)\n",
        "        self.output_activation = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        \"\"\"Forward pass; map latent vectors to samples.\"\"\"\n",
        "        intermediate = self.linear1(input_tensor)\n",
        "        intermediate = self.leaky_relu(intermediate)\n",
        "        intermediate = self.linear2(intermediate)\n",
        "        intermediate = self.leaky_relu(intermediate)\n",
        "        intermediate = self.linear3(intermediate)\n",
        "        intermediate = self.leaky_relu(intermediate)\n",
        "        intermediate = self.linear4(intermediate)\n",
        "        intermediate = self.output_activation(intermediate)\n",
        "\n",
        "        view = intermediate.view(-1, 18)\n",
        "        (view == view.max(dim=1, keepdim=True)[0]).view_as(intermediate).int()\n",
        "        \n",
        "        return intermediate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN3i4Xoq9mqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim, layers):\n",
        "        \"\"\"A discriminator for discerning real from generated samples.\n",
        "        params:\n",
        "            input_dim (int): width of the input\n",
        "            layers (List[int]): A list of layer widths including output width\n",
        "        Output activation is Sigmoid.\n",
        "        \"\"\"\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self._init_layers(layers)\n",
        "\n",
        "    def _init_layers(self, layers):\n",
        "        \"\"\"Initialize the layers and store as self.module_list.\"\"\"\n",
        "        self.module_list = nn.ModuleList()\n",
        "        last_layer = self.input_dim\n",
        "        for index, width in enumerate(layers):\n",
        "            self.module_list.append(nn.Linear(last_layer, width))\n",
        "            last_layer = width\n",
        "            if index + 1 != len(layers):\n",
        "                self.module_list.append(nn.LeakyReLU())\n",
        "            else:\n",
        "                self.module_list.append(nn.Sigmoid())\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        \"\"\"Forward pass; map samples to confidence they are real [0, 1].\"\"\"\n",
        "        intermediate = input_tensor\n",
        "        for layer in self.module_list:\n",
        "            intermediate = layer(intermediate)\n",
        "        return intermediate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXgni6k90HhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_inputs = []\n",
        "for j in range(len(all_sequences)):\n",
        "  embedding = sequence_to_vector(all_sequences[j])\n",
        "  all_inputs.append(np.reshape(embedding,378))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIaAh98vmoNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_function(batch_size, iteration):\n",
        "  input_array = all_inputs[batch_size*iteration : batch_size*(iteration+1)]\n",
        "  return input_array\n",
        "\n",
        "def noise_function(batch_size):\n",
        "  input_array = np.random.randn(batch_size,1,20)\n",
        "    # a = np.zeros([18,21])\n",
        "    # for i in range(18):\n",
        "    #   x = np.random.randint(21)\n",
        "    #   a[i][x] = 1\n",
        "    # input_array.append(np.reshape(a,378))\n",
        "  \n",
        "  return input_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gphmNsOt-ikc",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "class VanillaGAN():\n",
        "    def __init__(self, generator, discriminator, noise_fn, data_fn,\n",
        "                 batch_size=32, device='cpu', lr_d=1e-3, lr_g=2e-4):\n",
        "        \"\"\"A GAN class for holding and training a generator and discriminator\n",
        "        Args:\n",
        "            generator: a Ganerator network\n",
        "            discriminator: A Discriminator network\n",
        "            noise_fn: function f(num: int) -> pytorch tensor, (latent vectors)\n",
        "            data_fn: function f(num: int) -> pytorch tensor, (real samples)\n",
        "            batch_size: training batch size\n",
        "            device: cpu or CUDA\n",
        "            lr_d: learning rate for the discriminator\n",
        "            lr_g: learning rate for the generator\n",
        "        \"\"\"\n",
        "        self.generator = generator\n",
        "        self.generator = self.generator.to(device)\n",
        "        self.discriminator = discriminator\n",
        "        self.discriminator = self.discriminator.to(device)\n",
        "        self.noise_fn = noise_fn\n",
        "        self.data_fn = data_fn\n",
        "        self.batch_size = batch_size\n",
        "        self.device = device\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optim_d = optim.Adam(discriminator.parameters(),\n",
        "                                  lr=lr_d, betas=(0.5, 0.999))\n",
        "        self.optim_g = optim.Adam(generator.parameters(),\n",
        "                                  lr=lr_g, betas=(0.5, 0.999))\n",
        "        self.target_ones = torch.ones((batch_size, 1)).to(device)\n",
        "        self.target_zeros = torch.zeros((batch_size, 1)).to(device)\n",
        "\n",
        "    def generate_samples(self, latent_vec=None, num=None):\n",
        "        \"\"\"Sample from the generator.\n",
        "        Args:\n",
        "            latent_vec: A pytorch latent vector or None\n",
        "            num: The number of samples to generate if latent_vec is None\n",
        "        If latent_vec and num are None then us self.batch_size random latent\n",
        "        vectors.\n",
        "        \"\"\"\n",
        "        num = self.batch_size if num is None else num\n",
        "        latent_vec = self.noise_fn(num) if latent_vec is None else latent_vec\n",
        "        with torch.no_grad():\n",
        "            samples = self.generator(latent_vec)\n",
        "        return samples\n",
        "\n",
        "    def train_step_generator(self):\n",
        "        \"\"\"Train the generator one step and return the loss.\"\"\"\n",
        "        self.generator.zero_grad()\n",
        "\n",
        "        latent_vec = self.noise_fn(self.batch_size)\n",
        "        generated = self.generator(latent_vec)\n",
        "        classifications = self.discriminator(generated)\n",
        "        loss = self.criterion(classifications, self.target_ones)\n",
        "        loss.backward()\n",
        "        self.optim_g.step()\n",
        "        return loss.item()\n",
        "\n",
        "    def train_step_discriminator(self):\n",
        "        \"\"\"Train the discriminator one step and return the losses.\"\"\"\n",
        "        self.discriminator.zero_grad()\n",
        "\n",
        "        # real samples\n",
        "        real_samples = self.data_fn(self.batch_size)\n",
        "        pred_real = self.discriminator(real_samples)\n",
        "        loss_real = self.criterion(pred_real, self.target_ones)\n",
        "\n",
        "        # generated samples\n",
        "        latent_vec = self.noise_fn(self.batch_size)\n",
        "        with torch.no_grad():\n",
        "            fake_samples = self.generator(latent_vec)\n",
        "        pred_fake = self.discriminator(fake_samples)\n",
        "        loss_fake = self.criterion(pred_fake, self.target_zeros)\n",
        "\n",
        "        # combine\n",
        "        loss = (loss_real + loss_fake) / 2\n",
        "        loss.backward()\n",
        "        self.optim_d.step()\n",
        "        return loss_real.item(), loss_fake.item()\n",
        "\n",
        "    def train_step(self):\n",
        "        \"\"\"Train both networks and return the losses.\"\"\"\n",
        "        loss_d = self.train_step_discriminator()\n",
        "        loss_g = self.train_step_generator()\n",
        "        return loss_g, loss_d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC7m2z-iXxGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def simpleGAN(generator_func, discriminator_func, \n",
        "              batch_size: int = 25, epochs: int = 5, \n",
        "              max_data: int = len(all_sequences), print_every: int = 10, ):\n",
        "\n",
        "  #Array to monitor losses\n",
        "  loss_g = []\n",
        "  loss_dreal = []\n",
        "  loss_dfake = []\n",
        "  outputs = []\n",
        "  input_length = 20\n",
        "\n",
        "  # Models\n",
        "  generator = generator_func\n",
        "  discriminator = discriminator_func\n",
        "\n",
        "  # Optimizers\n",
        "  generator_optimizer = torch.optim.Adam(generator.parameters(), lr=0.01)\n",
        "  discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), \n",
        "                                          lr=0.001)\n",
        "\n",
        "  # loss\n",
        "  loss = nn.BCELoss()\n",
        "\n",
        "  for i in range(epochs):\n",
        "\n",
        "    for j in range(int(max_data/batch_size)):\n",
        "\n",
        "      # zero the gradients on each iteration\n",
        "      generator_optimizer.zero_grad()\n",
        "\n",
        "\n",
        "      # Create noisy input for generator\n",
        "      # Need float type instead of int\n",
        "      noise = noise_function(batch_size)\n",
        "      noise_data = torch.tensor(noise).float()\n",
        "      generated_data = generator(noise_data)  \n",
        "\n",
        "      # Generate examples of real data\n",
        "      true_data = data_function(batch_size, j)\n",
        "      true_labels = torch.tensor(np.ones(batch_size)).float()\n",
        "      true_data = torch.tensor(true_data).float()\n",
        "\n",
        "      # Train the generator\n",
        "      # We invert the labels here and don't train the discriminator because we want the generator\n",
        "      # to make things the discriminator classifies as true.\n",
        "      generator_discriminator_out = discriminator(generated_data)\n",
        "      generator_loss = loss(generator_discriminator_out, true_labels)\n",
        "      generator_loss.backward()\n",
        "      generator_optimizer.step()\n",
        "\n",
        "      # Train the discriminator on the true/generated data\n",
        "      discriminator_optimizer.zero_grad()\n",
        "      true_discriminator_out = discriminator(true_data)\n",
        "      true_discriminator_loss = loss(true_discriminator_out, true_labels)\n",
        "\n",
        "      # add .detach() here think about this\n",
        "      generator_discriminator_out = discriminator(generated_data.detach())\n",
        "      generator_discriminator_loss = loss(generator_discriminator_out, torch.zeros(batch_size))\n",
        "      discriminator_loss = (true_discriminator_loss + generator_discriminator_loss) / 2   \n",
        "      discriminator_loss.backward()\n",
        "      discriminator_optimizer.step()\n",
        "\n",
        "      loss_g.append(generator_loss.detach().numpy())\n",
        "      loss_dreal.append(true_discriminator_loss.detach().numpy())\n",
        "      loss_dfake.append(generator_discriminator_loss.detach().numpy())\n",
        "  \n",
        "\n",
        "    \n",
        "    generated_data = generated_data.detach().numpy()\n",
        "#      x = random.randint(0,len(generated_data))\n",
        "    sequences = set()\n",
        "    \n",
        "    for j in range(batch_size):\n",
        "      sequence = np.reshape(generated_data[j], [18,21])\n",
        "      sequences.add(vector_to_sequence(sequence))\n",
        "\n",
        "    seq_update = list(sequences)\n",
        "    outputs.append(seq_update)\n",
        "\n",
        "    if i % print_every == 0:\n",
        "\n",
        "      print(\"Currently at epoch: \" + str(i))\n",
        "\n",
        "  return loss_g, loss_dreal, loss_dfake, outputs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jUxoWZeFFy5",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Default title text\n",
        "def main():\n",
        "    from time import time\n",
        "    epochs = 600\n",
        "    batches = 10\n",
        "    generator = Generator(360)\n",
        "    discriminator = Discriminator(1, [64, 32, 1])\n",
        "    noise_fn = noise_function()\n",
        "    data_fn = data_function()\n",
        "    gan = VanillaGAN(generator, discriminator, noise_fn, data_fn, device='cpu')\n",
        "    loss_g, loss_d_real, loss_d_fake = [], [], []\n",
        "    start = time()\n",
        "    for epoch in range(epochs):\n",
        "        loss_g_running, loss_d_real_running, loss_d_fake_running = 0, 0, 0\n",
        "        for batch in range(batches):\n",
        "            lg_, (ldr_, ldf_) = gan.train_step()\n",
        "            loss_g_running += lg_\n",
        "            loss_d_real_running += ldr_\n",
        "            loss_d_fake_running += ldf_\n",
        "        loss_g.append(loss_g_running / batches)\n",
        "        loss_d_real.append(loss_d_real_running / batches)\n",
        "        loss_d_fake.append(loss_d_fake_running / batches)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} ({int(time() - start)}s):\"\n",
        "              f\" G={loss_g[-1]:.3f},\"\n",
        "              f\" Dr={loss_d_real[-1]:.3f},\"\n",
        "              f\" Df={loss_d_fake[-1]:.3f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v5ReVWzaZeJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5bdee817-08e5-4357-ee1b-36c0cf57527e"
      },
      "source": [
        "import time\n",
        "\n",
        "torch.manual_seed(1104)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "generator = Generator(20)\n",
        "discriminator = Discriminator(378, [32, 16, 1])  \n",
        "\n",
        "losses = simpleGAN(generator, discriminator, \n",
        "                   batch_size=2059, epochs=40000, print_every = 500)\n",
        "\n",
        "outputs = losses[3]\n",
        "\n",
        "print(\"Program took\", time.time() - start_time, \"to run\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([2059])) that is different to the input size (torch.Size([2059, 1, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([2059])) that is different to the input size (torch.Size([2059, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently at epoch: 0\n",
            "Currently at epoch: 500\n",
            "Currently at epoch: 1000\n",
            "Currently at epoch: 1500\n",
            "Currently at epoch: 2000\n",
            "Currently at epoch: 2500\n",
            "Currently at epoch: 3000\n",
            "Currently at epoch: 3500\n",
            "Currently at epoch: 4000\n",
            "Currently at epoch: 4500\n",
            "Currently at epoch: 5000\n",
            "Currently at epoch: 5500\n",
            "Currently at epoch: 6000\n",
            "Currently at epoch: 6500\n",
            "Currently at epoch: 7000\n",
            "Currently at epoch: 7500\n",
            "Currently at epoch: 8000\n",
            "Currently at epoch: 8500\n",
            "Currently at epoch: 9000\n",
            "Currently at epoch: 9500\n",
            "Currently at epoch: 10000\n",
            "Currently at epoch: 10500\n",
            "Currently at epoch: 11000\n",
            "Currently at epoch: 11500\n",
            "Currently at epoch: 12000\n",
            "Currently at epoch: 12500\n",
            "Currently at epoch: 13000\n",
            "Currently at epoch: 13500\n",
            "Currently at epoch: 14000\n",
            "Currently at epoch: 14500\n",
            "Currently at epoch: 15000\n",
            "Currently at epoch: 15500\n",
            "Currently at epoch: 16000\n",
            "Currently at epoch: 16500\n",
            "Currently at epoch: 17000\n",
            "Currently at epoch: 17500\n",
            "Currently at epoch: 18000\n",
            "Currently at epoch: 18500\n",
            "Currently at epoch: 19000\n",
            "Currently at epoch: 19500\n",
            "Currently at epoch: 20000\n",
            "Currently at epoch: 20500\n",
            "Currently at epoch: 21000\n",
            "Currently at epoch: 21500\n",
            "Currently at epoch: 22000\n",
            "Currently at epoch: 22500\n",
            "Currently at epoch: 23000\n",
            "Currently at epoch: 23500\n",
            "Currently at epoch: 24000\n",
            "Currently at epoch: 24500\n",
            "Currently at epoch: 25000\n",
            "Currently at epoch: 25500\n",
            "Currently at epoch: 26000\n",
            "Currently at epoch: 26500\n",
            "Currently at epoch: 27000\n",
            "Currently at epoch: 27500\n",
            "Currently at epoch: 28000\n",
            "Currently at epoch: 28500\n",
            "Currently at epoch: 29000\n",
            "Currently at epoch: 29500\n",
            "Currently at epoch: 30000\n",
            "Currently at epoch: 30500\n",
            "Currently at epoch: 31000\n",
            "Currently at epoch: 31500\n",
            "Currently at epoch: 32000\n",
            "Currently at epoch: 32500\n",
            "Currently at epoch: 33000\n",
            "Currently at epoch: 33500\n",
            "Currently at epoch: 34000\n",
            "Currently at epoch: 34500\n",
            "Currently at epoch: 35000\n",
            "Currently at epoch: 35500\n",
            "Currently at epoch: 36000\n",
            "Currently at epoch: 36500\n",
            "Currently at epoch: 37000\n",
            "Currently at epoch: 37500\n",
            "Currently at epoch: 38000\n",
            "Currently at epoch: 38500\n",
            "Currently at epoch: 39000\n",
            "Currently at epoch: 39500\n",
            "Program took 9335.723873376846 to run\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drm_MN96pPUJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "433b5667-0ac0-4733-f22f-23ac946d630b"
      },
      "source": [
        "loss_g = losses[0]\n",
        "loss_dreal = losses[1]\n",
        "loss_dfake = losses[2]\n",
        "#plt.plot(loss_g, label = 'generator')\n",
        "#plt.plot(loss_dreal, label ='discriminator_Real')\n",
        "plt.plot(loss_dfake, label = 'discrimininator_Fake')\n",
        "plt.xlabel('Update')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff85fe71d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEjvvIz6kBNX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "389c09c9-5b6a-4c19-be88-848033f67a7d"
      },
      "source": [
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-c5b7e396cfc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlsIG8LP8rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('outputs.txt', 'w') as f:\n",
        "    for item in outputs:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmh3YVl-dUdx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f770d220-dbc5-46c1-dbb5-45f9b4abdd68"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('outputs.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_eef95cb7-9641-437f-9485-af1408629683\", \"outputs.txt\", 7089768)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7BrMAa4zcC7",
        "colab_type": "text"
      },
      "source": [
        "##NEW CODE - SeqGAN implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGWs2msGddLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pdb\n",
        "import math\n",
        "import torch.nn.init as init\n",
        "from math import ceil\n",
        "import numpy as np\n",
        "import sys\n",
        "import torch.optim as optim\n",
        "import pandas as pd"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grt5UNBW6Chv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/preetham-v/antiviralGAN/master/AVPdb_data.csv'\n",
        "\n",
        "data = pd.read_csv(url, skiprows = 1, usecols = range(3), header=None, names=['ID','seq','len'])\n",
        "\n",
        "all_sequences = np.asarray(data['seq'])\n",
        "\n",
        "#Dictionary of 20 canonical amino acids\n",
        "CHARACTER_DICT = {\n",
        "    'A': 1, 'C': 2, 'E': 3, 'D': 4, 'F': 5, 'I': 6, 'H': 7, \n",
        "    'K': 8, 'M': 9, 'L': 10, 'N': 11, 'Q': 12, 'P': 13, 'S': 14, \n",
        "    'R': 15, 'T': 16, 'W': 17, 'V': 18, 'Y': 19, 'G': 20}\n",
        "\n",
        "INDEX_DICT = {\n",
        "    1: 'A', 2: 'C', 3: 'E', 4: 'D', 5: 'F', 6: 'I', 7: 'H',\n",
        "    8: 'K', 9: 'M', 10: 'L', 11: 'N', 12: 'Q', 13: 'P', 14: 'S',\n",
        "    15: 'R', 16: 'T', 17: 'W', 18: 'V', 19: 'Y', 20: 'G'}\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 18"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EptLKy7U6V3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sequence_to_vector(sequence, embed_dict=None):\n",
        "    if embed_dict==None:\n",
        "        default = np.asarray([21]*(MAX_SEQUENCE_LENGTH))\n",
        "#        default = np.asarray([21]*(MAX_SEQUENCE_LENGTH + 1))\n",
        "#        default[0] = 0\n",
        "        for i, character in enumerate(sequence[:MAX_SEQUENCE_LENGTH]):\n",
        "            default[i] = CHARACTER_DICT[character]\n",
        "#            default[i+1] = CHARACTER_DICT[character]\n",
        "        return default.astype(int)\n",
        "    else:\n",
        "        default = np.zeros([MAX_SEQUENCE_LENGTH,len(embed_dict['A'])])\n",
        "        for i, character in enumerate(sequence[:MAX_SEQUENCE_LENGTH]):\n",
        "            for k,val in enumerate(embed_dict[character]):\n",
        "                default[i,k] = val\n",
        "        return default\n",
        "\n",
        "def vector_to_sequence(vector):\n",
        "    seq = ''\n",
        "\n",
        "    for i in range(0,18):\n",
        "        arg = vector[i]\n",
        "        if arg == 21:\n",
        "          seq += 'X'\n",
        "        elif arg == 0:\n",
        "          seq += '0'\n",
        "        else:\n",
        "          seq += INDEX_DICT[arg]\n",
        "\n",
        "    return seq\n"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuUZiwOlAxIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_sequences = np.asarray(data['seq'])\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for i in range(len(all_sequences)):\n",
        "\n",
        "  all_data.append(sequence_to_vector(all_sequences[i]))"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeMYph9vEzBk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "41a9972b-b776-4dbd-f896-ecd98a226b79"
      },
      "source": [
        "print(all_data[0])"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[13 19 18 20 14 20 10 19 15 15 21 21 21 21 21 21 21 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvGgl0eizU6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, max_seq_len, gpu=False, oracle_init=False):\n",
        "        super(Generator, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.vocab_size = vocab_size\n",
        "        self.gpu = gpu\n",
        "\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim)\n",
        "        self.gru2out = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "        # initialise oracle network with N(0,1)\n",
        "        # otherwise variance of initialisation is very small => high NLL for data sampled from the same model\n",
        "        if oracle_init:\n",
        "            for p in self.parameters():\n",
        "                init.normal(p, 0, 1)\n",
        "\n",
        "    def init_hidden(self, batch_size=1):\n",
        "        h = autograd.Variable(torch.zeros(1, batch_size, self.hidden_dim))\n",
        "\n",
        "        if self.gpu:\n",
        "            return h.cuda()\n",
        "        else:\n",
        "            return h\n",
        "\n",
        "    def forward(self, inp, hidden):\n",
        "        \"\"\"\n",
        "        Embeds input and applies GRU one token at a time (seq_len = 1)\n",
        "        \"\"\"\n",
        "        # input dim                                             # batch_size\n",
        "        emb = self.embeddings(inp)                              # batch_size x embedding_dim\n",
        "        emb = emb.view(1, -1, self.embedding_dim)               # 1 x batch_size x embedding_dim\n",
        "        out, hidden = self.gru(emb, hidden)                     # 1 x batch_size x hidden_dim (out)\n",
        "        out = self.gru2out(out.view(-1, self.hidden_dim))       # batch_size x vocab_size\n",
        "        out = F.log_softmax(out, dim=1)\n",
        "        return out, hidden\n",
        "\n",
        "    def sample(self, num_samples, start_letter=0):\n",
        "        \"\"\"\n",
        "        Samples the network and returns num_samples samples of length max_seq_len.\n",
        "        Outputs: samples, hidden\n",
        "            - samples: num_samples x max_seq_length (a sampled sequence in each row)\n",
        "        \"\"\"\n",
        "\n",
        "        samples = torch.zeros(num_samples, self.max_seq_len).type(torch.LongTensor)\n",
        "\n",
        "        h = self.init_hidden(num_samples)\n",
        "        inp = autograd.Variable(torch.LongTensor([start_letter]*num_samples))\n",
        "\n",
        "        if self.gpu:\n",
        "            samples = samples.cuda()\n",
        "            inp = inp.cuda()\n",
        "\n",
        "        for i in range(self.max_seq_len):\n",
        "            out, h = self.forward(inp, h)               # out: num_samples x vocab_size\n",
        "            out = torch.multinomial(torch.exp(out), 1)  # num_samples x 1 (sampling from each row)\n",
        "            samples[:, i] = out.view(-1).data\n",
        "\n",
        "            inp = out.view(-1)\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def batchNLLLoss(self, inp, target):\n",
        "        \"\"\"\n",
        "        Returns the NLL Loss for predicting target sequence.\n",
        "        Inputs: inp, target\n",
        "            - inp: batch_size x seq_len\n",
        "            - target: batch_size x seq_len\n",
        "            inp should be target with <s> (start letter) prepended\n",
        "        \"\"\"\n",
        "\n",
        "        loss_fn = nn.NLLLoss()\n",
        "        batch_size, seq_len = inp.size()\n",
        "        inp = inp.permute(1, 0)           # seq_len x batch_size\n",
        "        target = target.permute(1, 0)     # seq_len x batch_size\n",
        "        h = self.init_hidden(batch_size)\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        for i in range(seq_len):\n",
        "            out, h = self.forward(inp[i], h)\n",
        "            loss += loss_fn(out, target[i])\n",
        "\n",
        "        return loss     # per batch\n",
        "\n",
        "    def batchPGLoss(self, inp, target, reward):\n",
        "        \"\"\"\n",
        "        Returns a pseudo-loss that gives corresponding policy gradients (on calling .backward()).\n",
        "        Inspired by the example in http://karpathy.github.io/2016/05/31/rl/\n",
        "        Inputs: inp, target\n",
        "            - inp: batch_size x seq_len\n",
        "            - target: batch_size x seq_len\n",
        "            - reward: batch_size (discriminator reward for each sentence, applied to each token of the corresponding\n",
        "                      sentence)\n",
        "            inp should be target with <s> (start letter) prepended\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size, seq_len = inp.size()\n",
        "        inp = inp.permute(1, 0)          # seq_len x batch_size\n",
        "        target = target.permute(1, 0)    # seq_len x batch_size\n",
        "        h = self.init_hidden(batch_size)\n",
        "\n",
        "        loss = 0\n",
        "        for i in range(seq_len):\n",
        "            out, h = self.forward(inp[i], h)\n",
        "            # TODO: should h be detached from graph (.detach())?\n",
        "            for j in range(batch_size):\n",
        "                loss += -out[j][target.data[i][j]]*reward[j]     # log(P(y_t|Y_1:Y_{t-1})) * Q\n",
        "\n",
        "        return loss/batch_size"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr3pIMHP1Rlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, max_seq_len, gpu=False, dropout=0.2):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.gpu = gpu\n",
        "\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, bidirectional=True, dropout=dropout)\n",
        "        self.gru2hidden = nn.Linear(2*2*hidden_dim, hidden_dim)\n",
        "        self.dropout_linear = nn.Dropout(p=dropout)\n",
        "        self.hidden2out = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        h = autograd.Variable(torch.zeros(2*2*1, batch_size, self.hidden_dim))\n",
        "\n",
        "        if self.gpu:\n",
        "            return h.cuda()\n",
        "        else:\n",
        "            return h\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        # input dim                                                # batch_size x seq_len\n",
        "        emb = self.embeddings(input)                               # batch_size x seq_len x embedding_dim\n",
        "        emb = emb.permute(1, 0, 2)                                 # seq_len x batch_size x embedding_dim\n",
        "        _, hidden = self.gru(emb, hidden)                          # 4 x batch_size x hidden_dim\n",
        "        hidden = hidden.permute(1, 0, 2).contiguous()              # batch_size x 4 x hidden_dim\n",
        "        out = self.gru2hidden(hidden.view(-1, 4*self.hidden_dim))  # batch_size x 4*hidden_dim\n",
        "        out = torch.tanh(out)\n",
        "        out = self.dropout_linear(out)\n",
        "        out = self.hidden2out(out)                                 # batch_size x 1\n",
        "        out = torch.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "    def batchClassify(self, inp):\n",
        "        \"\"\"\n",
        "        Classifies a batch of sequences.\n",
        "        Inputs: inp\n",
        "            - inp: batch_size x seq_len\n",
        "        Returns: out\n",
        "            - out: batch_size ([0,1] score)\n",
        "        \"\"\"\n",
        "\n",
        "        h = self.init_hidden(inp.size()[0])\n",
        "        out = self.forward(inp, h)\n",
        "        return out.view(-1)\n",
        "\n",
        "    def batchBCELoss(self, inp, target):\n",
        "        \"\"\"\n",
        "        Returns Binary Cross Entropy Loss for discriminator.\n",
        "         Inputs: inp, target\n",
        "            - inp: batch_size x seq_len\n",
        "            - target: batch_size (binary 1/0)\n",
        "        \"\"\"\n",
        "\n",
        "        loss_fn = nn.BCELoss()\n",
        "        h = self.init_hidden(inp.size()[0])\n",
        "        out = self.forward(inp, h)\n",
        "        return loss_fn(out, target)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI9bydIE1e0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_generator_batch(samples, start_letter=0, gpu=False):\n",
        "    \"\"\"\n",
        "    Takes samples (a batch) and returns\n",
        "    Inputs: samples, start_letter, cuda\n",
        "        - samples: batch_size x seq_len (Tensor with a sample in each row)\n",
        "    Returns: inp, target\n",
        "        - inp: batch_size x seq_len (same as target, but with start_letter prepended)\n",
        "        - target: batch_size x seq_len (Variable same as samples)\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size, seq_len = samples.size()\n",
        "\n",
        "    inp = torch.zeros(batch_size, seq_len)\n",
        "    target = samples\n",
        "    inp[:, 0] = start_letter\n",
        "    inp[:, 1:] = target[:, :seq_len-1]\n",
        "\n",
        "    inp = inp.type(torch.LongTensor)\n",
        "    target = target.type(torch.LongTensor)\n",
        "\n",
        "    if gpu:\n",
        "        inp = inp.cuda()\n",
        "        target = target.cuda()\n",
        "\n",
        "    return inp, target\n",
        "\n",
        "\n",
        "def prepare_discriminator_data(pos_samples, neg_samples, gpu=False):\n",
        "    \"\"\"\n",
        "    Takes positive (target) samples, negative (generator) samples and \n",
        "    prepares inp and target data for discriminator.\n",
        "    Inputs: pos_samples, neg_samples\n",
        "        - pos_samples: pos_size x seq_len\n",
        "        - neg_samples: neg_size x seq_len\n",
        "    Returns: inp, target\n",
        "        - inp: (pos_size + neg_size) x seq_len\n",
        "        - target: pos_size + neg_size (boolean 1/0)\n",
        "    \"\"\"\n",
        "\n",
        "    inp = torch.cat((pos_samples, neg_samples), 0).type(torch.LongTensor)\n",
        "    target = torch.ones(pos_samples.size()[0] + neg_samples.size()[0])\n",
        "    target[pos_samples.size()[0]:] = 0\n",
        "\n",
        "    # shuffle\n",
        "    perm = torch.randperm(target.size()[0])\n",
        "    target = target[perm]\n",
        "    inp = inp[perm]\n",
        "\n",
        "#    inp = Variable(inp)\n",
        "#    target = Variable(target)\n",
        "\n",
        "    if gpu:\n",
        "        inp = inp.cuda()\n",
        "        target = target.cuda()\n",
        "\n",
        "    return inp, target\n",
        "\n",
        "\n",
        "def batchwise_sample(gen, num_samples, batch_size):\n",
        "    \"\"\"\n",
        "    Sample num_samples samples batch_size samples at a time from gen.\n",
        "    Does not require gpu since gen.sample() takes care of that.\n",
        "    \"\"\"\n",
        "\n",
        "    samples = []\n",
        "    for i in range(int(ceil(num_samples/float(batch_size)))):\n",
        "        samples.append(gen.sample(batch_size))\n",
        "\n",
        "    return torch.cat(samples, 0)[:num_samples]\n",
        "\n",
        "def batchwise_oracle_nll(gen, oracle, num_samples, batch_size, max_seq_len, start_letter=0, gpu=False):\n",
        "    s = batchwise_sample(gen, num_samples, batch_size)\n",
        "    oracle_nll = 0\n",
        "    for i in range(0, num_samples, batch_size):\n",
        "        inp, target = prepare_generator_batch(s[i:i+batch_size], start_letter, gpu)\n",
        "        oracle_loss = oracle.batchNLLLoss(inp, target) / max_seq_len\n",
        "        oracle_nll += oracle_loss.data.item()\n",
        "\n",
        "    return oracle_nll/(num_samples/batch_size)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXoe3ru3Z5C0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "634ebf10-972f-41e6-c431-39311c23a537"
      },
      "source": [
        "gen = Generator(3, 32, 21, 19, False, True)\n",
        "a = batchwise_sample(gen, 100, 20)\n",
        "print(a.shape)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 19])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsiTcSyy1iyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CUDA = False\n",
        "VOCAB_SIZE = 22\n",
        "MAX_SEQ_LEN = 19\n",
        "START_LETTER = 0\n",
        "BATCH_SIZE = 32\n",
        "MLE_TRAIN_EPOCHS = 100\n",
        "ADV_TRAIN_EPOCHS = 50\n",
        "POS_NEG_SAMPLES = 2059\n",
        "\n",
        "GEN_EMBEDDING_DIM = 32\n",
        "GEN_HIDDEN_DIM = 20\n",
        "DIS_EMBEDDING_DIM = 32\n",
        "DIS_HIDDEN_DIM = 20"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJi2eS9t2BeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_generator_MLE(gen, gen_opt, oracle, real_data_samples, epochs):\n",
        "    \"\"\"\n",
        "    Max Likelihood Pretraining for the generator\n",
        "    \"\"\"\n",
        "    for epoch in range(epochs):\n",
        "        print('epoch %d : ' % (epoch + 1), end='')\n",
        "        sys.stdout.flush()\n",
        "        total_loss = 0\n",
        "\n",
        "        for i in range(0, POS_NEG_SAMPLES, BATCH_SIZE):\n",
        "            inp, target = prepare_generator_batch(real_data_samples[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
        "                                                          gpu=CUDA)\n",
        "            gen_opt.zero_grad()\n",
        "            loss = gen.batchNLLLoss(inp, target)\n",
        "            loss.backward()\n",
        "            gen_opt.step()\n",
        "\n",
        "            total_loss += loss.data.item()\n",
        "\n",
        "            if (i / BATCH_SIZE) % ceil(\n",
        "                            ceil(POS_NEG_SAMPLES / float(BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
        "                print('.', end='')\n",
        "                sys.stdout.flush()\n",
        "\n",
        "        # each loss in a batch is loss per sample\n",
        "        total_loss = total_loss / ceil(POS_NEG_SAMPLES / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
        "\n",
        "        # sample from generator and compute oracle NLL\n",
        "        oracle_loss = batchwise_oracle_nll(gen, oracle, POS_NEG_SAMPLES, BATCH_SIZE, MAX_SEQ_LEN,\n",
        "                                                   start_letter=START_LETTER, gpu=CUDA)\n",
        "\n",
        "        print(' average_train_NLL = %.4f, oracle_sample_NLL = %.4f' % (total_loss, oracle_loss))\n",
        "\n",
        "\n",
        "def train_generator_PG(gen, gen_opt, oracle, dis, num_batches):\n",
        "    \"\"\"\n",
        "    The generator is trained using policy gradients, using the reward from the discriminator.\n",
        "    Training is done for num_batches batches.\n",
        "    \"\"\"\n",
        "\n",
        "    for batch in range(num_batches):\n",
        "        s = gen.sample(BATCH_SIZE*2)        # 64 works best\n",
        "        inp, target = prepare_generator_batch(s, start_letter=START_LETTER, gpu=CUDA)\n",
        "        rewards = dis.batchClassify(target)\n",
        "\n",
        "        gen_opt.zero_grad()\n",
        "        pg_loss = gen.batchPGLoss(inp, target, rewards)\n",
        "        pg_loss.backward()\n",
        "        gen_opt.step()\n",
        "\n",
        "    # sample from generator and compute oracle NLL\n",
        "    oracle_loss = batchwise_oracle_nll(gen, oracle, POS_NEG_SAMPLES, BATCH_SIZE, MAX_SEQ_LEN,\n",
        "                                                   start_letter=START_LETTER, gpu=CUDA)\n",
        "\n",
        "    print(' oracle_sample_NLL = %.4f' % oracle_loss)\n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nFTuxWK2fn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_discriminator(discriminator, dis_opt, real_data_samples, generator, oracle, d_steps, epochs):\n",
        "    \"\"\"\n",
        "    Training the discriminator on real_data_samples (positive) and generated samples from generator (negative).\n",
        "    Samples are drawn d_steps times, and the discriminator is trained for epochs epochs.\n",
        "    \"\"\"\n",
        "\n",
        "    # generating a small validation set before training (using oracle and generator)\n",
        "    pos_val = oracle.sample(100)\n",
        "    neg_val = generator.sample(100)\n",
        "    val_inp, val_target = prepare_discriminator_data(pos_val, neg_val, gpu=CUDA)\n",
        "\n",
        "    for d_step in range(d_steps):\n",
        "        s = batchwise_sample(generator, POS_NEG_SAMPLES, BATCH_SIZE)\n",
        "#        print(s.shape, real_data_samples.shape)\n",
        "        dis_inp, dis_target = prepare_discriminator_data(real_data_samples, s, gpu=CUDA)\n",
        "        for epoch in range(epochs):\n",
        "            print('d-step %d epoch %d : ' % (d_step + 1, epoch + 1), end='')\n",
        "            sys.stdout.flush()\n",
        "            total_loss = 0\n",
        "            total_acc = 0\n",
        "\n",
        "            for i in range(0, 2 * POS_NEG_SAMPLES, BATCH_SIZE): #2 * POS_NEG_SAMPLES because both pos \n",
        "                                                                #and neg samples included in dis_inp\n",
        "                inp, target = dis_inp[i:i + BATCH_SIZE], dis_target[i:i + BATCH_SIZE]\n",
        "                dis_opt.zero_grad()\n",
        "                out = discriminator.batchClassify(inp)\n",
        "                loss_fn = nn.BCELoss()\n",
        "                loss = loss_fn(out, target)\n",
        "                loss.backward()\n",
        "                dis_opt.step()\n",
        "\n",
        "                total_loss += loss.data.item()\n",
        "                total_acc += torch.sum((out>0.5)==(target>0.5)).data.item()\n",
        "\n",
        "                if (i / BATCH_SIZE) % ceil(ceil(2 * POS_NEG_SAMPLES / float(\n",
        "                        BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
        "                    print('.', end='')\n",
        "                    sys.stdout.flush()\n",
        "\n",
        "            total_loss /= ceil(2 * POS_NEG_SAMPLES / float(BATCH_SIZE))\n",
        "            total_acc /= float(2 * POS_NEG_SAMPLES)\n",
        "\n",
        "            val_pred = discriminator.batchClassify(val_inp)\n",
        "            print(' average_loss = %.4f, train_acc = %.4f, val_acc = %.4f' % (\n",
        "                total_loss, total_acc, torch.sum((val_pred>0.5)==(val_target>0.5)).data.item()/200.))\n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zclPsKwXWiJ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "c35519c7-a93f-415a-8513-11cb71f8f80f"
      },
      "source": [
        "inp, target = prepare_generator_batch(torch.Tensor(all_data))\n",
        "dis = Discriminator(DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "dis_optimizer = optim.Adagrad(dis.parameters())\n",
        "gen = Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA, oracle_init=True)\n",
        "oracle = Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "train_discriminator(dis, dis_optimizer, target, gen, oracle, 100, 2)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".... average_loss = 0.0089, train_acc = 0.9981, val_acc = 0.9850\n",
            "d-step 93 epoch 2 : .... average_loss = 0.0075, train_acc = 0.9981, val_acc = 0.9950\n",
            "d-step 94 epoch 1 : .... average_loss = 0.0079, train_acc = 0.9973, val_acc = 0.9900\n",
            "d-step 94 epoch 2 : .... average_loss = 0.0084, train_acc = 0.9973, val_acc = 0.9850\n",
            "d-step 95 epoch 1 : .... average_loss = 0.0053, train_acc = 0.9988, val_acc = 0.9900\n",
            "d-step 95 epoch 2 : .... average_loss = 0.0059, train_acc = 0.9988, val_acc = 0.9900\n",
            "d-step 96 epoch 1 : .... average_loss = 0.0069, train_acc = 0.9976, val_acc = 0.9900\n",
            "d-step 96 epoch 2 : .... average_loss = 0.0065, train_acc = 0.9978, val_acc = 0.9900\n",
            "d-step 97 epoch 1 : .... average_loss = 0.0107, train_acc = 0.9971, val_acc = 0.9900\n",
            "d-step 97 epoch 2 : .... average_loss = 0.0117, train_acc = 0.9971, val_acc = 0.9900\n",
            "d-step 98 epoch 1 : .... average_loss = 0.0100, train_acc = 0.9968, val_acc = 0.9900\n",
            "d-step 98 epoch 2 : .... average_loss = 0.0097, train_acc = 0.9971, val_acc = 0.9900\n",
            "d-step 99 epoch 1 : .... average_loss = 0.0107, train_acc = 0.9973, val_acc = 0.9900\n",
            "d-step 99 epoch 2 : .... average_loss = 0.0100, train_acc = 0.9966, val_acc = 0.9900\n",
            "d-step 100 epoch 1 : .... average_loss = 0.0120, train_acc = 0.9964, val_acc = 0.9900\n",
            "d-step 100 epoch 2 : .... average_loss = 0.0101, train_acc = 0.9964, val_acc = 0.9900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik6kKYPcBhm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CUDA = False\n",
        "VOCAB_SIZE = 22\n",
        "MAX_SEQ_LEN = 18\n",
        "START_LETTER = 0\n",
        "BATCH_SIZE = 1030\n",
        "MLE_TRAIN_EPOCHS = 50\n",
        "ADV_TRAIN_EPOCHS = 50\n",
        "POS_NEG_SAMPLES = 2059\n",
        "\n",
        "GEN_EMBEDDING_DIM = 3\n",
        "GEN_HIDDEN_DIM = 32\n",
        "DIS_EMBEDDING_DIM = 3            \n",
        "DIS_HIDDEN_DIM = 32\n",
        "\n",
        "D_STEPS = 25\n",
        "D_EPOCHS = 2"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y8IoAPo2ktX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f2ef138b-a876-49a9-f552-b60be9788f03"
      },
      "source": [
        "%%capture cap --no-stderr\n",
        "# MAIN\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    oracle = Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA, oracle_init=True)\n",
        "    # a new oracle can be generated by passing oracle_init=True in the generator constructor\n",
        "    # samples for the new oracle can be generated using batchwise_sample()\n",
        "\n",
        "    gen = Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "    dis = Discriminator(DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "\n",
        "    # if CUDA:\n",
        "    #   oracle = oracle.cuda()\n",
        "    #   gen = gen.cuda()\n",
        "    #   dis = dis.cuda()\n",
        "    #   oracle_samples = oracle_samples.cuda()\n",
        "\n",
        "    oracle_samples = torch.Tensor(all_data)\n",
        "\n",
        "    # GENERATOR MLE TRAINING\n",
        "    print('Starting Generator MLE Training...')\n",
        "    gen_optimizer = optim.Adam(gen.parameters(), lr=1e-2)\n",
        "    train_generator_MLE(gen, gen_optimizer, oracle, torch.Tensor(all_data), MLE_TRAIN_EPOCHS)\n",
        "\n",
        "    # torch.save(gen.state_dict(), pretrained_gen_path)\n",
        "    # gen.load_state_dict(torch.load(pretrained_gen_path))\n",
        "\n",
        "    # PRETRAIN DISCRIMINATOR\n",
        "    print('\\nStarting Discriminator Training...')\n",
        "    dis_optimizer = optim.Adagrad(dis.parameters())\n",
        "    train_discriminator(dis, dis_optimizer, oracle_samples, gen, oracle, D_STEPS, D_EPOCHS)\n",
        "\n",
        "    # ADVERSARIAL TRAINING\n",
        "    print('\\nStarting Adversarial Training...')\n",
        "    oracle_loss = batchwise_oracle_nll(gen, oracle, POS_NEG_SAMPLES, BATCH_SIZE, MAX_SEQ_LEN,\n",
        "                                               start_letter=START_LETTER, gpu=CUDA)\n",
        "    print('\\nInitial Oracle Sample Loss : %.4f' % oracle_loss)\n",
        "\n",
        "    for epoch in range(ADV_TRAIN_EPOCHS):\n",
        "        print('\\n--------\\nEPOCH %d\\n--------' % (epoch+1))\n",
        "        # TRAIN GENERATOR\n",
        "        print('\\nAdversarial Training Generator : ', end='')\n",
        "        sys.stdout.flush()\n",
        "        train_generator_PG(gen, gen_optimizer, oracle, dis, 1)\n",
        "\n",
        "        # TRAIN DISCRIMINATOR\n",
        "        print('\\nAdversarial Training Discriminator : ')\n",
        "        train_discriminator(dis, dis_optimizer, oracle_samples, gen, oracle, 5, 3)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hU8zk3o2wbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = gen.sample(25).tolist()"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fmpv0lmfGof",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "af16d569-d721-428b-eec1-7ad87611fff3"
      },
      "source": [
        "for i in range(25):\n",
        "  print(vector_to_sequence(a[i]))"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KKTADNHSTHTVLAXXXX\n",
            "RWRGGRTRAQIGEDHXXX\n",
            "LGALGSGPLLRIVGLKLT\n",
            "DEPFTPPAVVDALYEATL\n",
            "TRCALAKARNYLFQDFNE\n",
            "MFALPHAPWELQIRLLAK\n",
            "MRRRELNKRAAGGLELKR\n",
            "RSKHLLIGGGNDXXXXXX\n",
            "GLVAAGHWXXXXXXXXXX\n",
            "ARQIRRFWVLNARSXXXX\n",
            "LIRNAIRVLGRKVTAAAV\n",
            "GRSLDAFNLSYQAEARKX\n",
            "CQLINVGSSNINAMVDXX\n",
            "DDRCNTQEVEFIEKAALA\n",
            "PIESQTWNAXXXXXXXXX\n",
            "VSPKXXXXXXXXXXXXXX\n",
            "SDLGARDEHTXXXXXXXX\n",
            "ELEKEERKVALWTFTYAL\n",
            "GPKMLETNVLDFTVGDFP\n",
            "LIGHRIMVFWKSCKSXXX\n",
            "AKVHSHALAALLXXXXXX\n",
            "LFTTLKNNPALXXXXXXX\n",
            "DKEAVTDVRNASTVXXXX\n",
            "FTRRKKKKAXXXXXXXXX\n",
            "VHVTACLGTQDMAEELXX\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vPKOBIsfHU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('output.txt', 'w') as f:\n",
        "    f.write(cap.stdout)"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7kAuBfImGd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "file1 = open('output.txt', 'r') \n",
        "lines = file1.readlines() \n",
        "\n",
        "loss_g = []\n",
        "loss_d = []\n",
        "\n",
        "for line in lines:\n",
        "\n",
        "  reg_lossg = re.search('oracle_sample_NLL = ([-+]?[0-9]*\\.?[0-9]+)', line)\n",
        "  reg_lossd = re.search('average_loss = ([-+]?[0-9]*\\.?[0-9]+)', line)  \n",
        "  if reg_lossg:\n",
        "    loss_g.append(float(reg_lossg.group(1)))\n",
        "  if reg_lossd:\n",
        "    loss_d.append(float(reg_lossd.group(1)))"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKHI3oUu755P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "1c552bee-2e31-4cea-8617-7606e6df1e55"
      },
      "source": [
        "plt.plot(loss_g)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1962b65ba8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxcVdnA8d+TmWyTpFmn6ZKte0tL15QuQAu0LAJSFxCQVVHkFRUQV1xwedUXxQVEgUpFREBZqiCgFAq0QGkhXei+L2nSJE3SNHtmPe8fM0mzZ5JMmuTm+X4+/bSZe+fOuVzy5OQ5zzlHjDEopZQa/CL6uwFKKaXCQwO6UkpZhAZ0pZSyCA3oSillERrQlVLKIuz99cFpaWkmJyenvz5eKaUGpY0bN5YZY5ztHeu3gJ6Tk0NeXl5/fbxSSg1KInKko2OaclFKKYvQgK6UUhahAV0ppSxCA7pSSlmEBnSllLIIDehKKWURGtCVUsoiLBvQX9xSSHWDp7+boZRSp40lA3pxZQN3/H0Lr2wt6u+mKKXUaWPJgF7n9gJQ4/L2c0uUUur0sWRAd3n9ANS6fP3cEqWUOn0sHdDrPNpDV0oNHdYM6J5Az7zerT10pdTQYcmA7vYFe+ga0JVSQ4glA7rL0xjQNeWilBo6rBnQvdpDV0oNPZYM6G5fIJBrQFdKDSWWDOiNKRcdFFVKDSUhBXQRuUNEtovIDhG5s5Pz5oqIV0SuDF8Tu6+pDl1z6EqpIaTLgC4i04AvAmcBM4DLRWR8O+fZgPuAVeFuZHe5vdpDV0oNPaH00KcAG4wxdcYYL7AG+FQ7530VeAE4Hsb29YjLqzl0pdTQE0pA3w6cKyKpIuIALgUym58gIqOBTwIPd3YhEblVRPJEJK+0tLSnbe6SS3voSqkhqMuAbozZxalUyn+BLUDrSPk74NvGGH8X11pujMk1xuQ6nc4eNrlrjSkXt8+Px9dpk5RSyjLsoZxkjFkBrAAQkZ8DBa1OyQX+LiIAacClIuI1xvwrjG0NWWMPHQJpl8RYSxbzKKVUCyEFdBEZbow5LiJZBPLn85sfN8aMaXbuX4CX+yuYw6kcOgTSLomxkf3VFKWUOm1CCujACyKSCniA240xJ0XkNgBjzCN91roeatlD19JFpdTQEGrK5dx2Xms3kBtjbu5lm3qtdcpFKaWGAksmlxtnioIGdKXU0GHJgO72+QmMz2rKRSk1dFgyoLs8PobFBAZCtRZdKTVUWDOge/0kOwIBvVYDulJqiLBkQHd7/SQ6ogCo15SLUmqIsGRAd3l9pAR76DooqpQaKiwa0P1Nk4k0oCulhgpLBnS3109slI2YyAitclFKDRmWDOgur59ouw1HlF176EqpIcOiAd1HlD0CR5RNyxaVUkOG5QK6MSbYQw8EdO2hK6WGCssFdK/fYAxE2yOIjbLrvqJKqSHDcgG9cWGuKHsEjkhNuSilhg7rBXRPIIBH223ERWvKRSk1dFguoLuDW841plzqPRrQlVJDQ0gBXUTuEJHtIrJDRO5s5/h1IrJVRLaJyDoRmRH+poamcencxpSL1qErpYaKLgO6iEwDvgicBcwALheR8a1OOwQsNsacCfwUWB7uhoaqMYcebbcRG2WjzqU9dKXU0BBKD30KsMEYU2eM8QJrCOwr2sQYs84YUxH8cj2QEd5mhs7tPZVycUTZqPP4MMb0V3OUUuq0CSWgbwfOFZFUEXEAlwKZnZx/C/CfcDSuJxo3iI6yRxAXbcfnN015daWUsrIu9xQ1xuwSkfuAVUAtsAVoN48hIucTCOjndHD8VuBWgKysrB42uXOuZj302EgbENjkItpu65PPU0qpgSKkQVFjzApjzBxjzCKgAtjb+hwRmQ48BiwzxpR3cJ3lxphcY0yu0+nsTbs71JRyibThiAoE8XBtclHd4KHwZH1YrqWUUuEWapXL8ODfWQTy50+3Op4FrARuMMa0CfanU2PKJVC22NhDD0+ly+/e2MelD7xDrUsrZ5RSA0+odegviMhO4N/A7caYkyJym4jcFjz+QyAV+KOIbBGRvL5obCiazxSNiwpklMI1uaigoo7Keg//3FwYlusppVQ4dZlDBzDGnNvOa480+/cXgC+EsV095mpV5QLhC+jlNW4A/vr+Ya6bl4WIhOW6SikVDpabKdq6Dh0I2+Si8lo3jigbe0tqeP9gu8MESinVb6wX0D2nyhYdYU65lNW4uGLGKJIdkfx13ZGwXFMppcLFcgG9+Vou4Uy5uL1+qhu8jE6K5eq5WazaWawVL0qpAcVyAb1xLZfmAT0cS+ieqA3kz1Pio7h+fqCG/ukN2ktXSg0c1gvoXj9RtghEpCnlEo5NLspqXACkxkWTkexg6ZR0/v7BUV1WQCk1YFguoLuD288BxERGIBLeHnpafBQAiyY6Ka91U1TZ0OtrK6VUOFguoLu8PqIjA7clIsEldHsf0MtrAz30lLhAQB8/PB6AA6U1vb62UkqFgwUDeiDl0ig2yh6egB6sQU+NjwZgnDMQ0Pcf14CulBoYLBfQ3V4/0ZGnFuJyRIVnk4uyGjeRNmFYTCAvnxYfRWJspPbQlVIDhuUCusvra8qhQ2NAD0cO3UVqXHTT7FARYZwzTnvoSqkBw4IB3U9Uq4AejkHR8hp3U/680fjh8Rwore31tZVSKhysF9A9/lY9dHt4Ui61blLjWwb0cc54SqtdVNZ7en19pZTqLcsFdLfP32Izi9gwpVzKa1ykBQdEG2mli1JqILFcQHd5fW1SLuHJobdNuWili1JqILFeQG835dK7gF7n9lLn9rVJuWQkxxJli9AeulJqQLBcQA+kXFoPivYuh95Yg54W1zLlYrdFMCYtjgPaQ1dKDQChbkF3h4hsF5EdInJnO8dFRB4Ukf0islVEZoe/qaFxedpWudR5fL1ac6Vx2n/rHjrAuOFxWumilBoQugzoIjIN+CJwFjADuFxExrc67WPAhOCfW4GHw9zOkAXq0FsOihoDDcFVGHui9bT/5sY74zlSXtu0l6lSSvWXUHroU4ANxpg6Y4wXWENgo+jmlgF/NQHrgSQRGRnmtoak+eJcQLN9RXuedilrTLm0qnIBGDc8Hr+Bw2V1Pb6+UkqFQygBfTtwroikiogDuBTIbHXOaOBos68Lgq+1ICK3ikieiOSVlpb2tM2daj2xKDYMm1ycWselnZSLc+CULr62o5iH3z7Q381QSvWTLgO6MWYXcB+wCvgvsAXoUXQ0xiw3xuQaY3KdTmdPLtEpn9/g9ZsWKZdw7Fp0otZFTOSpLe2aG+uMA/q/dLHO7eWeldt4YPVe/H5do12poSikQVFjzApjzBxjzCKgAtjb6pRCWvbaM4KvnVbuxg2iI1sOikLvUi7lNW5S49qmWwLXtzM6Kbbfe+hPvn+E8lo3DR4/BRW6NZ5SQ1GoVS7Dg39nEcifP93qlJeAG4PVLvOBSmNMUVhbGoLGgcnmy+c29qp7s55LWa27aWOL9owbHt+vPfRal5dH1x5kVGIMAHtLqvutLUqp/hNqHfoLIrIT+DdwuzHmpIjcJiK3BY+/ChwE9gN/Ar4c/qZ2zdVpD703OXRX0zro7RnvjOdAaQ3/3V5EcT/sYPTE+4c5UevmviunA7BP6+KVGpLaJoXbYYw5t53XHmn2bwPcHsZ29UhTyqWdHHpv9hU9UetmyshhHR4/d0Iaf9twhNv+tgmAsWlxvPiVs0mIiezxZwKsP1hOZoqD0UmxHZ5T3eBh+dqDXDB5OOdOcDIyMYZ92kNXakiy1EzRppSLveWORdDzlIsxJpBD7yTlcv7k4Wz70UX888sLueWcMRwsq2VPce+CalFlPTes2MDPX9nV6XmPvXOIk3Ue7lw6AQgsGLb3uAZ0pYYiSwX0xslDLevQe5dyqXZ5cfv8bab9txZttzErK5nr5mUBcLi8d3Xpf373EB6f4Z19pXh97U+KWrO3lN+/uY/Lp49kekYSABPTE9h/vEYrXZQagiwV0N2+tgE9tpdVLieCNejtzRJtT0aygwiB/PKeLwdQWe/h6Q35pA+LpqrBy5ajJ9ucs6+kmq88tYlJI4Zx36enN70+MT1eK12UGqIsFdBdwR5685RLtN1GlC2CGlfPeuiN0/47S7k0F2WPYFRSLEdO9LyH/rf1R6h1+3jgmllESKAn3tyJWje3PJFHdKSNx27KJS761FDI+OEJgFa6KDUUWSugB3PozQdFAeKibdS4erarUGfT/juSneroccqlwePj8fcOs2iik/ljU5mdlczbe1oG9G889xHFVQ386cY5bQZMJ6QHZq5qHl2pocdSAf1UlUvL24qPsVPb0x56J9P+O5KdGtfjlMvKTYWU1bi4bfFYABZPdLKtsJKymsBvCluOnuTN3ce5a+lEZmUlt3n/sJhIRibGsL+k/dLFBo+PzfkVPWqbUmpgs1RAb6xDj4lseVtxUXaqG3qYQ+9kpcWOZKc4qKjzdHuvUWMMf3rnINMzElkwNhWA8yYNB2BtMO3y0Jv7SYyN5IYF2R1ep7NKl3v+uY1P/nFdmzROb7m8Pnw6EKtUv7JkQI+ytUy5JMTYqXX1LKCX1bhJiLa3SeN0Jjs1sL5LfjfTLgdKazlUVss1c7MQEQCmjhpGWnwUa/aWsru4ijd2lXDzwhziozueQtBRpcubu0tYuakQW4Tws1d2dlg9013GGC5/8F1++vLOsFxPKdUzlgro7a3lAhAXbaemhwG9vNZNSjfSLRDIoQMcOdG9tMv6g+UALBiX2vRaRISwaIKTtXtL+f2b+4mLsvG5s3M6vU57lS6V9R7uWbmdSekJ/OYzM9hbUsOzeQXdal9Hthw9yb7jNfxne1GvNhJRSvWOpQL6qUHRVjn06F700Ktd3RoQBchKCQb0bvbQNxw6wfCEaHKCPxAaLZ7kpKLOwytbi7h+fjZJjs5/wLRX6fKzV3ZSWuPiV1dN54oZo8jNTuY3r+/p8Q+65l7ZGli2p6TKxR6trlGq31gsoLctW4RAQK/uccrF1enCXO2Ji7bjTIjmSDcGRo0xbDhYzvyxqU3plkbnTnAiErivW84d0+W1Wle6vLilkGfzCvjSorFMz0hCRPjeZVMoq3HzSC/XT/f7Da9uK+LM0YkArNnTN+vcK6W6FtJaLoNFUx26LYw99BoXZ41J6fb7slO6V7p4qKyW49Uu5o1t+1kpcVF8enYG2SkOhifEdHmtxkqXPcXV/Oq13fzhrQPMzkria0smNJ0zKyuZK2aM4pE1B3hu41G8PoOINA3Izh2TQmykDY/PjwhMHjEMW4S0+azNR09yrLKBb1w8ieVrD7J2XylfWjwu5PtWSoWPpQK62+fDHiHYbW1z6HXuQBVGe0GpIx6fn4o6T7dTLgBZqQ7W7S8P+fwNh04AMH9sarvH779qRrc+f/zweF7ccgyAa+Zm8uNlU9sM7P7g8jNIdkTS4PFjtwlur5+N+RW8uft4m+stmTyc3392VptNPl7ZWkSUPYILz0hnd3E1f3nvMLUub9Nkp+VrD1DT4OXrF03qsK1en58Gr7/Tgd5QvbOvlIxkB2PS4np9LaUGG0sFdJfH3ybdAoEqFwisuDisGysgnqgN1KA7E7of0HNS41i5qZAGj4+YyK4rZNYfLCctPpqxYQpEs7KSWX+wnB9fMY3PBteXac2ZEM2Pl01r83pJVQOb80/iNwZ7hLC/tIb7X9vDtcvXs+LmuU0/4BrTLYsnOkmIiWTxRCfL1x5k/cFylkxJZ//xav7vP7vxm0Dlz6fnZDR9ht9vyDtSwb8/Osar24rwG8O7376gxazX7jpUVssNKz4AYNFEJzfOz+aCycOJ6MYPcaUGM8vl0FsPiAJNQaK7aZfS6kANek966I2VLvkhLAEQyJ+fYP7YlDb58566/fxxrP/ukg6DeWfSh8VwybQRXHrmSC6aOoIvnzeeR66fw56Saj798Dq2FgTWltmUX0FxVQOXTw/sB56bk0xspK2pxv2+/+7BEWVnTnYyP3hxe9OuTuU1Lq5fsYHPPPo+z208ypSRw6io87BqZ3Gv7vmNnSUA3LpoLHuKq/jCX/P483uHenVNpQYTSwV0t9ffbr14Y0Cv6ebkotLg7ExnQvcGReFULXoolS5HyusormpgXgfplp6Itts63ZSjuy6aOoJnvjifWpeXKx56j8//5UMeXXuQKHsES6akN33mwnGprNlbSt7hE7y+s4TbFo/lD5+dTbQ9gq8+vZmNR07w8d+/y8YjFfxk2VQ2fv9C/vr5sxidFMu/Nh/rVRtf31XC5BEJ3HPpFN799gVMTI8P+wQqpQayULegu0tEdojIdhF5RkRiWh3PEpG3RGSziGwVkUv7prmdc3l97adcGgN6N3voZb3poTeVLnZd6bLhULD+vJ0B0YFkVlYyb33jPL558SQ25Vfw+s4Szp/kbJH7XjzJyZHyOr71/FaGJ0Tz+XPGMCIxhvuvmsHOoio+/fD7iAjP37aQGxfkEBdtJyJCWDZzFO/uL2ta4qC7Kmrd5B0+wYVnBH64RNoimJOdzJajJ3UpYTVkdBnQRWQ08DUg1xgzDbAB17Q67fvAs8aYWcFjfwx3Q0PRVcql2wG9BwtzNUpyRJIQYw+ph77+4AnS4qMY54zv9uecbgkxkdx+/nje/fYF/OyT0/jOx6a0OL54ohOAg2W13HXhxKZB1CVT0rn7wolcMnUEL33lbM7MSGzxvk/MGo3Pb3j5o5710t/acxy/gaXB3xYAZmUmU93g5WBZz5cyVmowCXUEyg7EiogHcACtv+sM0LhHW2I7x08Lt9ffZpYo0NSD7G4OvazGRWykrUcDdSJCTmpcl8voNtafzxvTtv58IIuPtnPdvLbryWSnxjE2LY6ICOGqZoOgAF9tVjbZ2sT0BKaMHMa/thzj5rO7rrVv7Y1dJQxPiG6qhweYlRXY9GNzfgXjhw/8H5ZK9VaXPXRjTCFwP5APFAGVxphVrU77EXC9iBQQ2DD6q+1dS0RuFZE8EckrLQ1/btPl9bepQYdTAb27C3SV1bhI60H+vFFWqqPLlMuvV+3lWGUDiyc5e/w5A83jn5vLk7ec1aZ8tCufmDmKLUdPcribPWqX18eaPaUsmZLeoqJlnDOehGh7uxuEKGVFoaRckoFlwBhgFBAnIte3Ou1a4C/GmAzgUuBJEWlzbWPMcmNMrjEm1+kMfwBzeX3tDorGx/S8h96TdEuj7BQHhRX1HS6C9eDqfTz01n6uPSurTW92MMtOjWNkYscbW3fkipmjEKGpfj5U6w+eoNbt48Izhrd4PSJCmJGZxOZ8DehqaAgll7AUOGSMKQUQkZXAQuBvzc65BbgEwBjzfnDQNA1oO0OlD7m9fuLi2t5SXHQgyHd/UNRNVqt1VbojJzUOr99QUFFPTqv68kfWHOA3r+/l07Mz+Nknpg2qdEtfGZkYy7wxKTzzQT6FJ+sorXZR4/IyIjGWzORYctLiuHBKOsmtljJ+Y2cJMZERLByX1uaaMzOTeHjNAerc3jaTogC+989tvH+gnKxUB9kpDj4+YxS5OQN7cFqpjoTyO3E+MF9EHBKIOkuA1lvR5wdfR0SmADHAaa8X6yjl0tNt6HrbQ5+dnYwIPLXhSIvX391Xxv/9ZzcfnzGKX145XSe+NHPD/BxO1rtZu7eMsho3ESJ8dPQky9ce5FvPb2Xez1fz5ac2smpHMe8fKOftPcd5fWcJ505wtjuBa1ZWEj6/YVtBZZtj6w+W89SGfIbFRlJa7eK5jQV8/i8f0uDp2WYoSvW3LnvoxpgNIvI8sAnwApuB5SLyEyDPGPMScDfwJxG5i8AA6c2mH9ZRdXn9RHcwKzMu2tatlIvX5+dEnbtHs0QbjR8ez5WzM3hi3RFumJ9DVqoDl9fHD1/cTnaqg19dOb1bSxEMBZdNH8llwYlKzXl9fvaUVLNyUyH/3FzIq9taTkL61rT2lxaYmRkYGN1y9GSLOn+/3/C/r+xkVGIMf791PjGRNt7bX8Z1j23gtR3FLJs5Oox3pdTpEVL5hjHmXuDeVi//sNnxncDZYWxXj7g7KFuEQB69OymXE7VujAFnN1dabO3uiybx8tYifvnabh767GxWvHuIg2W1/OVzc0NaEkAF2G0RTB2VyNRRiXz7kslsyq/AbwzRdhvx0XYmprdfxZIaH01WiqNNHv2fmwvZXljFA9fMbHoOC8amkpkSy98/OKoBXQ1K1lrLpYOJRRDYhq47Ab1xlmhvUi4AIxJj+OKisTy4eh8fm1bE71fv5+Kp6U1by6nui7JHdLiIWXtmZibxQXDxM4A6t5dfvbaHGZlJfHz6qKbXIyKEq3MzuX/VXg6X1bYZ91BqoLPU1H+Xp+MeekKMvVtT/5smFfUi5dLoS4vG4kyI5ivPbMJg+MHlZ/T6mip0s7KSKK5qoKiyHr/f8MDqfRRXNfCDy6a0Gb+4ck4mEQLP5h3tp9Yq1XPWCui+9tdygcBs0Vp3NwJ6L6b9t/fZd184EWPgqxdMICO555Uzqvsa8+i/f3M/F/9uLY+uOciyme1Xs4xIjOGCycN5bmMBnjDtuarU6WKZlIsxBre3/eVzITC5qDubNpc1pVx6l0NvdPXcTCaOSGBGRlJYrqdCd8aoYUTZInh6Qz6T0hN44JqZXN4s1dLa1XOzeGNXHm/tPs5FU0ecxpYq1TuWCeiN2891OCjazY2iy2pcRNsjwrLpAgSWApidlRyWa6nuibbbePDamUSIsLTVbNL2nD/JyfCEaJ7akK8BXQ0qlkm5uH3hDuhu0uKjdcKPRVwyLbC2eyg1/3ZbBDctzGHN3lL+8WH+aWidUuFhmYDeuJ9oRwG9cRu6UJdSDazjEr71xNXgctvicZwzPo0fvLijaUMPpQY66wR0b2B2X0eDok0rLoY4MFpa7ep1DboavGwRwoPXzsIZH83//G1T03aESg1klsmhuxtz6O0snwunFuiqcXlJCGFf0bIad9Pyq2poSomL4o/XzeaqR97nk398j/hoOydq3SQ5onjx9rM7HIBXqr9Y5v/IxkHR9tZyge7tK+rzG07U9m4dF2UNMzKT+O3VMxmeEM2IYTGMdcaxq6iKPcXV/d00pdqwTA+9PrigUkxU+ymXhG6siX6i1o3fhKcGXQ1+zdeXOXqijnN/+RZbCk622XVJqf5mmR56gzsQ0GM7XJyrsYfe9Up6ZWGa9q+sJyM5ltS4KD7STTPUAGSZgN7YQ+8ooMc37Svq6fJa4Z5UpKxDJLBphgZ0NRBZLqA7Oki5nAro3eiha9miaseMjCT2l9ZQ3dB150Cp08kyAb0umHLpaEnapiqXEL4Jy6qDC3NpykW1Y2ZWEsbQ7qYZSvUnywT0xl1mYjvooTduQ1frDq2HHmWLYFiMZcaMVRjNCA6GbhlCE46eyzvKgdKa/m6G6kJIAV1E7hKRHSKyXUSeCe4Z2vqcz4jIzuB5T4e/qZ2r72JQtHEbulCqXEprXKTFR+m0f9WuJEcUOamOQZVHN8b0OEV0sLSGbz6/lR+9tCPMrVLh1mVAF5HRwNeAXGPMNMAGXNPqnAnAd4GzjTFTgTv7oK2d6mpQFELfhq60Wqf9q84FBkYHR8qlwePjrn9sYfZPX2d7Yffb/NzGAgDe2VfG7uKqcDdPhVGoKRc7ECsidsABHGt1/IvAH4wxFQDGmOPha2Jo6j0+ou0RnS6+FB9jDymg7y6uZryz/S3NlILAwGhxVQPFlQ393ZROFVc28JlH3+dfW44RIcIDq/d16/0+v2HlpgLOykkhNtLGincO9VFLVTh0GdCNMYXA/UA+UARUGmNWtTptIjBRRN4TkfUickl71xKRW0UkT0TySktLe9v2Furdvg7z543iouxUdxHQS6oaKK12MW20ThpRHZsZXBbiowGcR99y9CRXPPQuB47XsPyGOXz5vPG8vrOEHcfa76Ufr2rgyofXsWbvqe/NtftKKaly8flzcrgqN4MXtxzjePXA/iE2lIWSckkGlgFjgFFAnIhc3+o0OzABOA+4FviTiLRZCMUYs9wYk2uMyXU6nb1tewv1bl+n6RYIbEPXVQ+98VdSnQWoOnPGyGHYI4Qt/ZRHf3nrMf7w1v4Oj7/00TE+8+j7REdGsPLLZ3PR1BHcfHYOCTF2fr+6/ff96rU95B2p4O5nt1AeLN19Lu8oKXFRXDA5nc+dPQaP38/f3j/SJ/ekei+UlMtS4JAxptQY4wFWAgtbnVMAvGSM8RhjDgF7CQT406be03VAjwthTfRthZWIBL5hlepITKSNKSOH9cvAqNvr58f/3smvV+2h8GR9i2N+v+E3r+/la89sZmZGEi/efg6TRiQAkBgbyefOHsN/dxSzq6hlLnxbQSXPbyrgkqkjqKr3cs8/t1FR6+aNncf5xMzRRNkjGJMWx5LJ6Ty5/khTVZkaWEIJ6PnAfBFxSKDsYwmwq9U5/yLQO0dE0gikYA6GsZ1davCEkHIJIaBvL6xknDO+aakApToyIzORrQWVvLuvjMKT9SGvtd9b/91RTGm1C7+Bf3zYcjPrh9cc4MHV+7hqTgZPfuEsUuJaznb+/Nk5xEfbeejNU710Yww/eXkHKY4ofnnVdL5x8URe21HC/zy1EbfPz1W5GU3nfuHcMVTUeXhhU0Hf3qTqkVBy6BuA54FNwLbge5aLyE9E5Irgaa8B5SKyE3gL+KYxpryP2tyuUHroCdF2arooW9xWWMm0Udo7V107Z7yTGpeX61ds4Oz/e5N5v1jN4bLakN/v9voxpvs/BJ5Yd5icVAfnTkjj2Q+P4g3u1nWyzs0jbx/gwjPS+eWV09vdGyDJEcXNC3N4dXsR//vyTooq63l1WzEfHq7g7osmMSwmklvOGctZY1JYf/AEZ45OZEqz31bnjUlhRkYif3zrgPbSB6CQqlyMMfcaYyYbY6YZY24wxriMMT80xrwUPG6MMV83xpxhjDnTGPP3vm12W3WhDIpGd55DP17dQEmVDoiq0FwybQQf3LOEZ744n//9xDSqGzwhV5HUuLws+MVqHl3b8S+yxhie2nCE/2wranpte2ElG49UcMOCHK6bl01xVQNv7wkMYj72ziFq3F7uvmhip3MobjtvHMtmjOLxdYc59763+O7KrReFv/IAABdYSURBVEwekcDVczOBwOYev75qBmnxUdy0MKfFe0WEb148mcKT9Ty1QbfnG2gsM1O03u3rcNp/o/hoO7WdbEPXNCCqAV2FaPiwGBaMS+X6+dnctCCHF7cUsv/4qRmVR0/UcdOfP2hTv/3K1mOU17p56M397e6GVO/2ccfft/C9f27ny09v4tm8QGrliXWHcUTZuHJOBkumDMeZEM3TH+RzotbN4+8d4rIzRzJ5ROe/YcZH2/ndNbN4+xvncf38bGKjbPz4iqnYmpX8ZqY4+PB7S7lyTkab958zIY2zx6fyh7f2d2ufXtX3LBPQG0JIuXS1Dd22gipEYKoGdNUDty4aS0ykjQeDvfQGj4/b/raRNXtLeeCNlj335zcWkD4smjq3l0fWHGhx7NjJeq56dB3/3nqMb1w0kXPGp/HtF7ay4t1DvPjRMT45azSJsZFE2iK4OjeTt/cc50cv7aDO4+POpaHXImSmOPjRFVPZcM9S5o1NbXO8s17+ty6ezIlaN4+9E/gNo/BkPbc9uZHfrNoT8uer8LNMQK/3+DpcabFR823o2rP9WCVj0uKaAr9S3ZEaH82NC3L499Zj7C2p5t4Xd7DjWBXzxqTw2o5ijp6oA+BQWS0fHq7g5oVj+OSsDJ5Yd7hpgtLu4iqW/eE9jpTVseKmXL5ywQT+dGMuC8am8tOXd+L2+lukQa6em4khUKa4bMYoxg9POC33OiMziY9NG8Gf1h5kxbuHuPi3a/nvjmKe2pDfo3EBFR7WCeghpFy62oZue2GlpltUr9y6aCyOSBtfeCKPf+Qd5asXjOeBa2YRIcLj7x0G4IWNBUQIfGr2aO5cOgG/MTyweh+b8iu4+tH1RAi88OWFXDA5HQiUSK64aS5LJg/n4zNGMTH9VNDOTHFw7gQntgjhjqUTT+u93n3RJOo9Pn768k7OHJ3I7eePo7zWzeHyutPaDnWKZbqi9SGULSZ0siZ6WY2LosoGDeiqV1Liorj57Bz+8NYBzhmfxp1LJ2KLEC6fPpJn845yx5IJvLCpgEUTnaQPC6xxd928bJ5cf4QXtxTiTIjmb7fMIzPF0eK6sVE2Vtw8t93P/N9l0zhUXsuYtLg+v7/mxg+P5xefOhOAq+Zksr+0hj+8dYCNRypOe1tUgCV66B6fH4/PhDSxCGi3dHFbcEB06igN6Kp3bls8jm9ePIkHr53VNNB4yzljqXF5uevZLRRVNrQYbLz9/PHERtrISnHw3G0L2gTzrmSlOlg8Mbwzr0N19dwsrp6bRUSEMN4Zz7AYOxuPnOjw/Je3HuNLT+ZpWqaPWKKH3hDCSovQfNeitgF9e3CzgqmjtQZd9U5CTCS3nz++xWtnZiRy1pgU3tx9nMTYSJZOSW865kyI5o2vLybJEdll2nAgi4gQZmcnk3e4ot3jxhgeXL2PvSU1bC+s0uU1+oAleuj1XWxu0aizgL6tMDAgOiwmMvwNVAq45ZwxAFwxY1SbwD0iMWZQB/NGudnJ7DteQ2Vd27XXtxZUsrckUNL52o7i0920IcESAb3BHZgp12UPPabjQdHthZU6oUj1qaVT0rnn0slteu9WMic7BYBN+W176c/mHSUmMoIZGYka0PuIJQJ6nScQoLueKRo43rqHfryqgWOVDczMbLNApFJhY4sQbl00jhGJbTb8sowZmYnYIoS8Vnn0erePl7Yc49JpI/nkrNHsO17DQd3SLuwsEdC72n6uUeM2dJX1LX8dbFwCdWam9tCV6g1HlJ2po4a1yaO/tqOYapeXq3IzuWjqiOBrJV1ez+X18ae1B5u+x1XnrBHQgzn0UHKQk0cmsCW/5ZKnHxWcxB4hWuGiVBjMyU7mo4KTeIKLhkEg3ZKV4mDemBRGJcVy5uhEVu3sOu2yetdxfvbqLl76qLAvm2wZlgjojVUuXc0UBVgwLpXNRyuoazb9f8vRk0wemWCJQSml+tuc7GQaPH52HgusX3P0RB3rDpRz1ZyMpi0iL56azub8k5RUdb770QeHAqmb5rsoqY5ZIqDXNw6KhhLQx6bi8ZmmXwn9fsPWo5XMyND8uVLhkBscGM07UsG2gkru+ec2RODTzWrvLw6mXVbt7DztsiEY0N/ZV9a0TLDqmDUCeoh16ABzc1KwRwjvHwws136wrJZql1cHRJUKkxGJMYxOiuXXq/bw8YfeZXP+Sb59yWRGJcU2nTN+eDxj0uJY1Um1S2W9h93FVZwxchjVDV425Q/c/VsHipACuojcJSI7RGS7iDwjIu0O04vIp0XEiEhueJvZufpg+iSUlElctJ2ZmUmsOxAI6B81DYhqQFcqXC6fMZLhCdF8/7IprPvuBdy2eFyL4yLCJdNG8O7+Mm79ax7v7itrM3t005EKjIE7l07AHiG8vef46byFXlm7t5RPP7yOvMMdz5rtC6FsEj0a+BqQa4yZBtiAa9o5LwG4A9gQ7kZ2JdSJRY0WjEtlW8FJqho8bDl6kvhoO2Od8X3ZRKWGlO9+bApvf/N8vnDu2A4n633l/PHctngceUcquH7FBi578F2qGk5VoG04dIJIm7BoopPZ2clNG3kMZDWuwH6sN/75AzYeqeDnr+46rcschJpysQOxImIHHMCxds75KXAf0PkoRx+oD3FiUaMF41LxG/jw0Ak+KjjJ9IzEFov7K6X6Xly0nW9fMpl137mAn31yGjuLqni22R6pHx4ObIEXE2njvElOdhZVcbyLQdT+UO/2sWZvKT97ZScX/WYNz3yQz62LxvL9y6awKf9kU3r3dAhlT9FC4H4Cm0UXAZXGmFXNzxGR2UCmMeaVzq4lIreKSJ6I5JWWhu+nbb3HR5Q9IuSgPDsrmSh7BG/vKWVXURUzNN2iVL+JibRx3bxscrOTeeL9w/j8hgaPj60FJzlrTGDjjfMmDgfg7QFW7bKvpJqzfvYGN/35A55Yd4SctDie+9IC7rl0CtfPz8aZEN1iQ+6+FkrKJRlYBowBRgFxInJ9s+MRwG+Au7u6ljFmuTEm1xiT63SGb3W4UHYrai4m0sacrGRe2FSAx2e0wkWpAeDz54zh6Il6Vu8qYXP+STw+w1ljkgGYMjKB9GHRrBlgaZfnNhbQ4PXx+M1z2XLvhTz9xfnk5gSqfGIibXxp0VjWHShvswJlX6VhQkm5LAUOGWNKjTEeYCWwsNnxBGAa8LaIHAbmAy+dzoHROre3WwEdAmmXuuDsMx0QVar/XXRGOqOTYnn8vcN8cOgEIqfWhhERFk908s6+0gFTvmiM4dVtRZw9Po3zJw/HEdV28drPzssi2RHJQ2/ux+318/LWY1yz/H2e/qBvNtgOJaDnA/NFxCGBTQaXALsaDxpjKo0xacaYHGNMDrAeuMIYk9cnLW5Hvccf8oBoo4XjAr/KjRgWY+m1NZQaLOy2CG5YkM37B8t5ftNRJo8YRmLsqQHV8yYNp6rByw0rPuCuf2zhZ6/sbNq6LxQur6/F7NXe2nGsioKKei6dNrLDcxxRdr5w7lje2lPKwv9bzVee3kxBRT0x9r6ZxBhKDn0D8DywCdgWfM9yEfmJiFzRJ63qpnp391IuANMzknBE2Zih67coNWBcMzeTmMgIjp6oZ96YlBbHzpvk5GPTRlDj8vLh4RM8/t5hvvL0Jnz+rtMXDR4fyx56jzv+vjlsbf3P9iJsEcKFZ6R3et4NC7KZlJ7AjIwkHr95Lmu+eX6LSVbhFNIGF8aYe4F7W738ww7OPa+Xbeq2hhC2n2styh7BYzfmMrLZZAelVP9KckTxqdkZPL0hn7k5LQO6I8rOw9fPafr6hY0F3P3cR/z53UN8cdHYTq97/2t72F1czeHyWho8Lfcfrm7wsKuoGr8xGAPpw6K7LGM2xvCfbcUsGJtKclxUp+cOi4nktbsWdXpOuFhix6L6bg6KNlo4Pq0PWqOU6o0vnzeOerePRRM7//781OzR/HdHMb9atYfzJzsZPzyh3fPeP1DOivcOMWXkMHYVVZF3uIJzJpy69ndWbuOVrUUt3nPhGencsWQCU0cN44NDJ1i5qZADpTU8cO0sRifFsrekhoNltXw+uGnJQGGJgF7n9pHs6PynpFJqcMhIdvDbq2d2eZ6I8PNPnslFv13D3c9+xAv/sxC7rWUWubrBwzee+4jsFAdP3nIWC3/xJmv2Hm8K6DUuL2/sLOHjM0Zx7dxMkMCCYH9+9xCX7ywhLT6ashoXjigbAtywYgPPfWkBr24rQuTUmjQDhSUCek9SLkqpwc+ZEM1PPzGNrzy9mT+9c4j/Oa/lEgM/fXknRZX1PHfbQtLio5k7Jpm1e8v43mWB46t3leDy+rlxQXZTimfhuDQ+f84YnnjvMDuOVXHR1HQumTaCHcequGHFBm56/APq3T7m5qTgTIg+3bfcKWsszuX24dClb5Uaki6fPopLpo7gd2/s5Uh5bdPrq3eV8GxeAbctHsec7EA9+6IJTvaUVFNUWQ/Ay1uLGDEshjlZyS2uOSwmkq8umcAjN8zhU7MzcETZmZuTwsPXzWF3UTUHSmu5dNrA6p2DVQK69tCVGtJ+dMVUIm0RfP9f2zHGUFHr5jsrtzF5RAJ3LJ3QdN7iSYEJje/sLaO6wcOaPaVceubIpnXau3L+5OH8+jMzOGPkMC6d3nG5Yn+xRMqlvtWotVJqaBmRGMO3LpnED1/cwb+2FPLW7lIqat385XNziW5W8z0pPTjjdF8pdpvg9vm5rJuBednM0SybOTrctxAWgz6g+/wGt9ffoyoXpZR1XDcvm5WbCrln5XbqPT6+fuHENttKigiLJjhZtbOEWpeXUYkxzLLQTPFBn3I5tXTuoL8VpVQv2CKEX3zqTDw+P2eOTmwzQNpo0UQnlfUe3u5mumUwGPQ99MbdwGPbWUdBKTW0TBk5jH/dfjajk2KJtLXfyTtnfBoRAn4Dl88YdZpb2LcGfRRs6Mb2c0op65s2uvPlPJLjopiZmcTxahczMqy19MegD+jd2U9UKaUAfnf1LNw+P4H1Bq1j0Af0Orfm0JVS3ZOV6ujvJvSJQR8FG3PoWraolBrqBn1Ab8yht7e4vFJKDSWDPqBrDl0ppQIGf0B3a0BXSikIMaCLyF0iskNEtovIMyIS0+r410Vkp4hsFZHVIpLdN81tqy7YQ4/RQVGl1BDXZRQUkdHA14BcY8w0wAZc0+q0zcHj0wlsV/fLcDe0Iw3aQ1dKKSD0lIsdiBURO+AAjjU/aIx5yxhTF/xyPdA3G+a1Q3PoSikVEMom0YXA/UA+UARUGmNWdfKWW4D/tHdARG4VkTwRySstLe1Je9uo9/iIskW02alEKaWGmlBSLsnAMmAMMAqIE5HrOzj3eiAX+FV7x40xy40xucaYXKfT2fNWN1Pv9hETqcFcKaVCiYRLgUPGmFJjjAdYCSxsfZKILAW+B1xhjHGFt5kdq3fr5hZKKQWhBfR8YL6IOCSw8MESYFfzE0RkFvAogWB+PPzN7Fi9x6f5c6WUIrQc+gYClSubgG3B9ywXkZ+IyBXB034FxAPPicgWEXmprxrcWmD7OZ0lqpRSIUVCY8y9wL2tXv5hs+NLw9mo7mjw+IjVHLpSSlljpqjm0JVSygIBvc6tOXSllAILBPQGj0+XzlVKKSwQ0Os9PhyaclFKKWsEdE25KKWUFQK620eM9tCVUmpwB3Sf3+Dy+rWHrpRSDPKA3qArLSqlVJNBHdDrm/YT1YCulFKDO6AHN7fQskWllBrkAb0p5aI9dKWUGtwBvU63n1NKqSYa0JVSyiIGdUA/WhHYxnRUUmw/t0QppfrfoA7oe4uribZHkJni6O+mKKVUvxvcAf14DRPS47FFSH83RSml+l1IAV1E7hKRHSKyXUSeEZGYVsejReQfIrJfRDaISE5fNLa1vcXVTByecDo+SimlBrwuA7qIjAa+BuQaY6YBNuCaVqfdAlQYY8YDvwXuC3dDW6us91Bc1cDEERrQlVIKQk+52IFYEbEDDuBYq+PLgCeC/34eWBLcULrP7CupBmBienxffoxSSg0aoWwSXQjcD+QDRUClMWZVq9NGA0eD53uBSiC19bVE5FYRyRORvNLS0l41fG9JDQAT07WHrpRSEFrKJZlAD3wMMAqIE5Hre/JhxpjlxphcY0yu0+nsySWa7C2pJi7KxmgtWVRKKSC0lMtS4JAxptQY4wFWAgtbnVMIZAIE0zKJQHk4G9ranuJqJqQn0MeZHaWUGjRCCej5wHwRcQTz4kuAXa3OeQm4KfjvK4E3jTEmfM1sa9/xaiZpukUppZqEkkPfQGCgcxOwLfie5SLyExG5InjaCiBVRPYDXwe+00ftBaC8xkVZjZsJOiCqlFJN7KGcZIy5F7i31cs/bHa8AbgqjO3qVOOA6CQtWVRKqSaDcqbo3mDJoqZclFLqlEEb0BNjI3EmRPd3U5RSasAYtAF9kla4KKVUC4MuoBtjgiWLOiCqlFLNDbqAfrzaRVWDVwdElVKqlUEX0PcUBwZEJ+gqi0op1cKgC+iOKBtLp6RrD10ppVoJqQ59IMnNSeGxnJT+boZSSg04g66HrpRSqn0a0JVSyiI0oCullEVoQFdKKYvQgK6UUhahAV0ppSxCA7pSSlmEBnSllLII6eOd4jr+YJFS4EgP354GlIWxOYPFULzvoXjPMDTveyjeM3T/vrONMc72DvRbQO8NEckzxuT2dztOt6F430PxnmFo3vdQvGcI731rykUppSxCA7pSSlnEYA3oy/u7Af1kKN73ULxnGJr3PRTvGcJ434Myh66UUqqtwdpDV0op1YoGdKWUsohBF9BF5BIR2SMi+0XkO/3dnr4gIpki8paI7BSRHSJyR/D1FBF5XUT2Bf9O7u+29gURsYnIZhF5Ofj1GBHZEHzm/xCRqP5uYziJSJKIPC8iu0Vkl4gsGArPWkTuCv7/vV1EnhGRGCs+axH5s4gcF5HtzV5r9/lKwIPB+98qIrO781mDKqCLiA34A/Ax4AzgWhE5o39b1Se8wN3GmDOA+cDtwfv8DrDaGDMBWB382oruAHY1+/o+4LfGmPFABXBLv7Sq7zwA/NcYMxmYQeDeLf2sRWQ08DUg1xgzDbAB12DNZ/0X4JJWr3X0fD8GTAj+uRV4uDsfNKgCOnAWsN8Yc9AY4wb+Dizr5zaFnTGmyBizKfjvagLf4KMJ3OsTwdOeAD7RPy3sOyKSAVwGPBb8WoALgOeDp1jqvkUkEVgErAAwxriNMScZAs+awBaYsSJiBxxAERZ81saYtcCJVi939HyXAX81AeuBJBEZGepnDbaAPho42uzrguBrliUiOcAsYAOQbowpCh4qBtL7qVl96XfAtwB/8OtU4KQxxhv82mrPfAxQCjweTDM9JiJxWPxZG2MKgfuBfAKBvBLYiLWfdXMdPd9exbjBFtCHFBGJB14A7jTGVDU/ZgL1ppaqORWRy4HjxpiN/d2W08gOzAYeNsbMAmpplV6x6LNOJtAbHQOMAuJom5YYEsL5fAdbQC8EMpt9nRF8zXJEJJJAMH/KGLMy+HJJ469fwb+P91f7+sjZwBUicphAOu0CAvnlpOCv5WC9Z14AFBhjNgS/fp5AgLf6s14KHDLGlBpjPMBKAs/fys+6uY6eb69i3GAL6B8CE4Ij4VEEBlFe6uc2hV0wb7wC2GWM+U2zQy8BNwX/fRPw4uluW18yxnzXGJNhjMkh8GzfNMZcB7wFXBk8zVL3bYwpBo6KyKTgS0uAnVj8WRNItcwXEUfw//fG+7bss26lo+f7EnBjsNplPlDZLDXTNWPMoPoDXArsBQ4A3+vv9vTRPZ5D4FewrcCW4J9LCeSTVwP7gDeAlP5uax/+NzgPeDn477HAB8B+4Dkgur/bF+Z7nQnkBZ/3v4DkofCsgR8Du4HtwJNAtBWfNfAMgXECD4HfyG7p6PkCQqCS7wCwjUAVUMifpVP/lVLKIgZbykUppVQHNKArpZRFaEBXSimL0ICulFIWoQFdKaUsQgO6UkpZhAZ0pZSyiP8H/WUaMomAkkgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBV5pqLg_pna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}